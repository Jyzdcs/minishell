# üî§ Lexer - Analyseur Lexical

## üìã R√¥le du Module

Le **Lexer** (ou analyseur lexical) est la premi√®re √©tape du pipeline de traitement d'une commande shell. Il transforme une cha√Æne de caract√®res brute en une s√©quence de **tokens** (lex√®mes) typ√©s et structur√©s.

## üéØ Objectifs

1. **Tokenisation** : D√©couper l'input en unit√©s lexicales distinctes
2. **Classification** : Assigner un type √† chaque token (CMD, ARG, PIPE, REDIR, etc.)
3. **Gestion des quotes** : Respecter les r√®gles de protection des caract√®res sp√©ciaux
4. **Validation syntaxique** : D√©tecter les erreurs de syntaxe de base

## üîß Fonctions Principales √† Impl√©menter

### **Fonctions de Tokenisation**

```c
t_token *lexer(char *input);                    // Point d'entr√©e principal
t_token *create_token(char *value, t_type type); // Cr√©ation d'un token
void    add_token(t_token **list, t_token *new); // Ajout √† la liste
```

### **Gestion des Quotes**

```c
char    *handle_quotes(char *input, int *i);    // Extraction du contenu entre quotes
bool    is_quote_closed(char *input);           // V√©rification fermeture quotes
char    *remove_quotes(char *str);              // Suppression des quotes externes
```

### **Reconnaissance des Op√©rateurs**

```c
bool    is_operator(char c);                    // D√©tection caract√®res sp√©ciaux
t_type  get_operator_type(char *str);           // Type d'op√©rateur (|, <, >, etc.)
int     get_operator_len(char *str);            // Longueur de l'op√©rateur (>> = 2)
```

### **Utilitaires**

```c
void    skip_whitespace(char *str, int *i);     // Ignorer les espaces
bool    is_whitespace(char c);                  // Test caract√®re d'espacement
void    free_tokens(t_token *tokens);           // Lib√©ration m√©moire
```

## üèóÔ∏è Structure de Donn√©es

```c
typedef enum e_token_type {
    TOKEN_CMD,          // Commande (premier mot)
    TOKEN_ARG,          // Argument
    TOKEN_PIPE,         // |
    TOKEN_REDIR_IN,     // <
    TOKEN_REDIR_OUT,    // >
    TOKEN_REDIR_APPEND, // >>
    TOKEN_HEREDOC,      // <<
    TOKEN_EOF           // Fin de cha√Æne
} t_token_type;

typedef struct s_token {
    char            *value;
    t_token_type    type;
    struct s_token  *next;
} t_token;
```

## üìù R√®gles de Gestion

### **Quotes Simples (`'`)**

- Tout caract√®re est litt√©ral (pas d'expansion)
- Exemple : `'echo $HOME | ls'` ‚Üí un seul token ARG

### **Quotes Doubles (`"`)**

- Variables expand√©es (`$VAR` ‚Üí valeur)
- Op√©rateurs prot√©g√©s (`"|"` reste litt√©ral)
- Exemple : `"echo $HOME"` ‚Üí expansion de `$HOME`

### **Caract√®res Sp√©ciaux**

- `|` : s√©parateur de pipe
- `<`, `>`, `>>`, `<<` : redirections
- ` ` (espace) : s√©parateur de tokens

## üß™ Tests de Validation

```bash
# Tests basiques
echo hello world        # 3 tokens: CMD, ARG, ARG
ls | wc -l              # 4 tokens: CMD, PIPE, CMD, ARG

# Tests avec quotes
echo "hello world"      # 2 tokens: CMD, ARG
echo 'no $expansion'    # 2 tokens: CMD, ARG

# Tests redirections
cat < input.txt         # 3 tokens: CMD, REDIR_IN, ARG
echo hi > output.txt    # 4 tokens: CMD, ARG, REDIR_OUT, ARG
```

## ‚ö†Ô∏è Gestion d'Erreurs

- **Quotes non ferm√©es** : Retourner NULL ou token d'erreur
- **Op√©rateurs en fin de ligne** : `ls |` ‚Üí erreur syntaxique
- **S√©quences invalides** : `< >` ‚Üí erreur de redirection

## üîó Interface avec les Autres Modules

- **Input** : Cha√Æne brute depuis `readline()`
- **Output** : Liste cha√Æn√©e de tokens pour le **Parser**
- **D√©pendances** : Module **Utils** pour les fonctions auxiliaires
